---
title: "Replicability Lab 2"
author: "Data Science Team"
output: 
     html_document:
         keep_md: true
---

```{r, echo=FALSE}
BH<-function(p,alpha)
  {
    pw<-na.omit(p)
    n<-length(pw)
    pw<-sort(pw)
    comp<-(pw<(1:n)*alpha/n)
    outcome<-sum(comp==TRUE)    
    if(outcome>0){
      last<-max((1:n)[comp==TRUE])
      pcut<-pw[last]
      shr<-p*0
      shr[p<=pcut]<-1
      out<-list(shr,sum(shr>0,na.rm=T),pcut)
      names(out)<-c("Reject","Total.Rej","Pcut")
    }
    else
      {
        shr<-p*0
        out<-list(shr,outcome,0)
        names(out)<-c("Reject","Total.Rej","Pcut")
      }
    return(out)
    
  }
```

## Today's Activity

Today's activity will investigate the winner's curse: discoveries (even real ones!) sometimes lose 
some of their effect sizes as we replicate the experiments. 

### The winner's curse: regression towards the mean/shrinkage

We will generate data in two phases: first, we generate a "true" signal vector $v^{\rm true}$ of 
length $M = 1000$. The entries of $v^{\rm true}$ are all normally distributed, that is, 
$v_i^{\rm true} \sim \mathcal{N}(0, 1)$. Then
we generate an observation $y$ with $y = v^{\rm true} + W$ where $W$ is a noise vector, each entry of 
$W$ also having a normal distribution $\mathcal{N}(0,1)$.

```{r, echo=TRUE, eval=FALSE}
M<-1000
v.true <- rnorm(M)
y <- rnorm(M, v.true, 1)
```

Now, based on these data, draw four plots. First, you should generate 2 plots, where the first is a 
plot of the true mean $v^{\rm true}$ against the observed value $y$. Your first task is to complete 
the code below:

```{r, echo=TRUE, eval=FALSE}
par(mfcol=c(1,2))  # Generate a new panel of plots
plot(v.true, y,
     xlab="True Means", ylab="Observations", main="Scatterplot")
points(v.true, v.true, col="blue", pch=19)
abline(0, 1, col=2, lwd=2)  # Plot 45 degree line

plot(v.true, (y-v.true),
     xlab="True Means", ylab="y - v", main="Sorting by true means")
abline(0,0,col="red",lwd=2)
```

Now, let us change around the plot order. In particular, you should plot the true means $v^{\rm true}$ 
on the vertical axis against the observed means $y$ on the horizontal axis.

```{r, echo=TRUE, eval=FALSE}
par(mfcol = c(1,2))
plot(y, v.true,
     ylab="True Means v", xlab="Observations y", main="Flipped plot and 45 degree line")
abline(0, 1, col=2,lwd=2) # Plot 45 degree line

plot(y, y-v.true,
     xlab="Observation y", ylab="y - v", main="Sorting by observations")
abline(0,0,col="red",lwd=2)  # Plot horizontal line
```

**Task**
After you have implemented the code above, explain what you are observing.

### The winner's curse revisited: the effect of selective reporting

Now that we have seen some results on regression toward the mean, let us consider the effect of 
selective reporting, that is, that we can only publish results with p-values $p < \alpha$, where 
$\alpha$ is our pre-chosen significance level (e.g., .01 or .00001 or .05).

To that end, we generate $M = 1000$ test statistics, each from a normal distribution with mean $\mu = .3$. 
Thus, for each hypothesis, the null $H_0 : \mu = 0$ is false. We will then report whether $p < .05$ 
for this null, plotting the results.
(In other words, we observe $y = \mu + \mathcal{N}(0, 1)$ for each of 1000 test statistics.)

```{r, echo=T, eval=FALSE}
par(mfrow=c(1,3))
Tmean<-rep(0,1000) # initializing the vector of means
N<-1000 # number of non zero means
mu<-0.3 # signal strength
Tmean[1:N]<-mu # first N means are equal to mu 
y<-rnorm(1000,Tmean,1)
pvalue<-2*pnorm(-abs(y))
discoveries<-pvalue<0.05

# Plot 95% confidence interals for mu based on each of the 1000 test statistics:
lower<-y-1.96
upper<-y+1.96
plot(y,pch=20,main="All variables",ylim=c(min(lower),max(upper)),xlab="")
for(i in 1:length(y))
{
	{lines(c(i,i),c(lower[i],upper[i]),col=2)}
}

mtext(paste("true signal =",as.character(mu)),side=3,line=0)
points(1:1000,y,pch=20)
points(1:1000,Tmean,col="blue",pch=19)
mtext(paste("Average signal =",as.character(round(mean(y[1:N]),3))),side=1,line=2.5)
mtext(paste("Percent. of means covered =",as.character(round(sum((Tmean>=lower)*(Tmean<=upper))/1000,3))),side=1,line=4)

# Now plot confidence intervals only for the significant (=selected) test statistics:
plot(y,pch=20,main="Report if p-value<0.05",ylim=c(min(lower),max(upper)),xlab="")
lower<-y-1.96
upper<-y+1.96
for(i in 1:length(discoveries))
{
	if(discoveries[i]==1)
	{lines(c(i,i),c(lower[i],upper[i]),col=2)}
}
points(1:1000,y,pch=20)
points(1:1000,Tmean,col="blue",pch=19)

mtext(paste("Percent. of means covered =",as.character(round(sum((Tmean[discoveries==1]>=lower[discoveries==1])*(Tmean[discoveries==1]<=upper[discoveries==1]))/sum(discoveries==1),3))),side=1,line=4)


dy<-y[discoveries==1]
dlower<-lower[discoveries==1]
dupper<-upper[discoveries==1]
plot(dy,pch=20,main="Zooming on reports",ylim=c(min(lower),max(upper)),xlab="")
for(i in 1:length(dy))
{
	
	lines(c(i,i),c(dlower[i],dupper[i]),col=2)
}
points(1:length(dy),dy,pch=20)
points(1:length(dy),Tmean[discoveries==1],col="blue",pch=19)
```

After this code, the vector `dy` stores the $y$ values for the "discoveries", that is, 
the rejected null hypotheses.

**Task**

Calculate the mean values of $y$ on the rejected nulls with positive and negative $y$ values, respectively. 
What are these values?

```{r, echo=TRUE, eval=FALSE}
y_pos = y[y > 0]
mean(y_pos)
y_neg = y[y < 0]
mean(y_neg)

mean(dy[dy > 0])
mean(dy[dy <0])
mean(dy[dy > 0]) + mean(dy[dy <0])
```

How much larger are the positive $y$ "discoveries" than the true mean $\mu$?

### Winner's curse again: bias and confidence interval coverage

Now, we will use the Benjamini-Hochberg procedure that provides some correction for the fact that 
we are doing many tests.
In this case, we generate $M = 1000$ experiments, the first $N = 100$ of which have mean $\mu = 3$ 
and the remainder of which are all true nulls, that is, $\mu = 0$.

```{r, echo=TRUE, eval=FALSE}
Tmean<-rep(0,1000) # the majority is equal to 0
N<-100 # number of non zero means
mu<-3 # signal strength
Tmean[1:N]<-mu
y<-rnorm(1000,Tmean,1)
pvalue<-2*pnorm(-abs(y))
# Now, use Benjamini-Hochberg to get discoveries
discoveries<-BH(pvalue,0.05)[[1]]

lower<-y-1.96
upper<-y+1.96
par(mfrow=c(1,3))
plot(y,pch=20,main="All",ylim=c(min(lower),max(upper)),xlab="")
for(i in 1:length(discoveries))
{
	{lines(c(i,i),c(lower[i],upper[i]),col=2)}
}
points(1:1000,y,pch=20)
points(1:1000,Tmean,col="blue",pch=19)
mtext(paste("Percent. of means covered =",as.character(round(sum((Tmean>=lower)*(Tmean<=upper))/1000,3))),side=1,line=3)

plot(y,pch=20,main="Selected",ylim=c(min(lower),max(upper)),xlab="")
for(i in 1:length(discoveries))
{
	if(discoveries[i]==1)
	{lines(c(i,i),c(lower[i],upper[i]),col=2)}
}
points(1:1000,y,pch=20)
points(1:1000,Tmean,col="blue",pch=19)
mtext(paste("Percent. of means covered =",as.character(round(sum((Tmean[discoveries==1]>=lower[discoveries==1])*(Tmean[discoveries==1]<=upper[discoveries==1]))/sum(discoveries==1),3))),side=1,line=3)



dy<-y[discoveries==1]
dlower<-lower[discoveries==1]
dupper<-upper[discoveries==1]
plot(dy,pch=20,main="Zooming on selected",ylim=c(min(lower),max(upper)),xlab="")
for(i in 1:length(dy))
{
	
	lines(c(i,i),c(dlower[i],dupper[i]),col=2)
}
points(1:length(dy),dy,pch=20)
points(1:length(dy),Tmean[discoveries==1],col="blue",pch=19)
mtext(paste("Percent. of means covered =",as.character(round(sum((Tmean[discoveries==1]>=lower[discoveries==1])*(Tmean[discoveries==1]<=upper[discoveries==1]))/sum(discoveries==1),3))),side=1,line=3)
```

**Task**

Explain the plots just displayed. What is good about the discoveries you make? What is bad?
